{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:35:43.802981Z",
     "start_time": "2024-06-14T12:35:43.070114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are data science assistant helping me solve code-related problems in my machine learning tasks.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I have trained an explainable boosting machine (EBM) for a binary classification task to predict if a flight will be delayed or not. Write python code to enforce monotonic constraints on the 'Time' feature. If possible, use methods built into the ebm library.\"}\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T14:22:01.267224Z",
     "start_time": "2024-06-14T14:21:54.337034Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"To enforce monotonic constraints on a feature in an Explainable Boosting Machine (EBM) model using the ebm library in Python, you can use the `feature_names_c` parameter to specify the feature name with the required monotonic constraint. In this case, we want to enforce a monotonic constraint on the 'Time' feature. Below is the Python code snippet to achieve this:\\n\\n```python\\nfrom interpret.glassbox import ExplainableBoostingClassifier\\nfrom interpret import preserve\\nimport numpy as np\\n\\n# Assuming X_train, y_train are the training features and labels\\n# Assuming X_test, y_test are the test features and labels\\n\\n# Training the EBM model\\nebm = ExplainableBoostingClassifier(random_state=42)\\nebm.fit(X_train, y_train, feature_names=X_train.columns)\\n\\n# Enforce monotonicity constraint on the 'Time' feature\\nfeature_names_c = {'Time': np.array([1])}\\n\\n# Fit the EBM model with monotonic constraint\\nebm = ExplainableBoostingClassifier(random_state=42)\\nebm.fit(X_train, y_train, feature_names=X_train.columns, feature_pairs=feature_names_c)\\n\\n# Evaluate the model\\nebm_perf = ebm.score(X_test, y_test)\\n\\n# Preserve the EBM model\\npreserve(ebm, 'EBM_model.pkl')\\n```\\n\\nIn this code snippet, we first train the EBM model without any constraints. Then we define the monotonic constraint for the 'Time' feature by specifying the index of the feature and the direction of the constraint (1 for increasing, -1 for decreasing). Finally, we re-train the EBM model with the specified monotonic constraint.\\n\\nMake sure to modify the code according to your data and feature names. This code snippet assumes that your data is in a Pandas DataFrame format.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T14:32:47.239705Z",
     "start_time": "2024-06-14T14:32:47.232750Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Sure! The Explainable Boosting Machine (EBM) is part of the InterpretML package, which provides important tools for creating interpretable machine learning models. To apply monotonic constraints to a feature, you can use the `monotonize` method. Here's an example of how to do that for the `Time` feature in your EBM model:\\n\\nFirst, make sure you have installed the required package:\\n```bash\\npip install interpret\\n```\\n\\nThen, you can use the following Python code to train the EBM model and enforce a monotonic constraint on the 'Time' feature:\\n\\n```python\\nfrom interpret.glassbox import ExplainableBoostingClassifier\\nfrom interpret import show\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd\\n\\n# Sample dataset (replace this with your actual dataset)\\n# Assuming your dataset has columns 'Time', 'Feature1', ..., 'FeatureN', 'Delayed'\\ndata = {\\n    'Time': [10, 20, 30, 40, 50],  # Sample times\\n    'Feature1': [5, 6, 7, 8, 9],\\n    'Feature2': [1, 2, 3, 4, 5],\\n    'Delayed': [0, 1, 0, 1, 0]\\n}\\ndf = pd.DataFrame(data)\\n\\n# Splitting the dataset\\nX = df.drop(columns=['Delayed'])\\ny = df['Delayed']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Training the EBM model\\nebm = ExplainableBoostingClassifier(interactions=0)  # No pairwise interactions for simplicity\\nebm.fit(X_train, y_train)\\n\\n# Enforce monotonic constraint on 'Time' feature\\nfeature_names = X_train.columns\\ntime_feature_index = feature_names.tolist().index('Time')\\n\\n# Monotonize the model with monotonic increase for 'Time' (ensure the feature is non-decreasing)\\nebm.monotonize(time_feature_index, increasing=True)\\n\\n# Now the model is updated with the monotonic constraint\\n\\n# Evaluate or view the results\\nebm_global = ebm.explain_global()\\nshow(ebm_global)\\n```\\n\\nReplace the sample data with your actual data. This code assumes you have a DataFrame with the relevant features and target variable.\\n\\nAfter fitting the EBM model, the `monotonize` method is used to enforce a monotonic constraint such that the `Time` feature is non-decreasing (with `increasing=True`). If you need the feature to be non-increasing, you can set `increasing=False`.\\n\\nThe `show` method from `interpret` package is used to visualize the global explanations of the EBM model, which will show how each feature, including `Time`, influences the predictions.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Explicitly instruct model to use monotonize() method\n",
    "\n",
    "completion2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are data science assistant helping me solve code-related problems in my machine learning tasks.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I have trained an explainable boosting machine (EBM) for a binary classification task to predict if a flight will be delayed or not. Write python code to enforce monotonic constraints on the 'Time' feature using the EBM's monotonize method.\"}\n",
    "    ]\n",
    ")\n",
    "print(completion2.choices[0].message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T14:43:56.350212Z",
     "start_time": "2024-06-14T14:43:45.952241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Enforcing monotonic constraints in Explainable Boosting Machines (EBMs) can help improve your model\\'s interpretability and ensure that relationships between features and the outcome align with domain knowledge. For example, if you expect that longer flight times are more likely to lead to delays, you can enforce a monotonically increasing relationship for the \\'Time\\' feature.\\n\\nHere\\'s a step-by-step example of how to enforce monotonic constraints on the \\'Time\\' feature:\\n\\n1. Install the `interpret` package if you haven\\'t already.\\n2. Load your data.\\n3. Train the EBM model with the monotonic constraints.\\n\\nBelow is the example Python code illustrating these steps:\\n\\n```python\\n# Step 1: Install the necessary package\\n!pip install interpret\\n\\n# Step 2: Import necessary libraries\\nfrom interpret.glassbox import ExplainableBoostingClassifier\\nfrom interpret import show\\n\\n# Step 3: Load your dataset\\n# Replace this with your actual dataset loading code\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\n\\n# Example dataset loading\\ndata = pd.read_csv(\\'flights_data.csv\\')\\nX = data.drop(columns=[\\'delayed\\'])\\ny = data[\\'delayed\\']\\n\\n# Step 4: Train-test split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Step 5: Initialize and train the EBM with monotonic constraints\\n# Replace \\'Time\\' with the actual column name for flight time in your dataset if different\\nmonotonic_constraints = {\\'Time\\': 1}  # 1 for monotonically increasing, -1 for decreasing\\n\\nebm = ExplainableBoostingClassifier(monotonic_constraints=monotonic_constraints)\\nebm.fit(X_train, y_train)\\n\\n# Step 6: Evaluate the model (optional)\\nprint(\"Train accuracy:\", ebm.score(X_train, y_train))\\nprint(\"Test accuracy:\", ebm.score(X_test, y_test))\\n\\n# Step 7: Visualize the results (optional)\\nebm_global = ebm.explain_global()\\nshow(ebm_global)\\n```\\n\\n### Explanation:\\n1. **Installation**: You first need to install the `interpret` package which contains the implementation of EBM.\\n2. **Imports and Data Loading**: Import the necessary libraries, including `ExplainableBoostingClassifier` from the `interpret.glassbox` module. Load your dataset into a DataFrame.\\n3. **Train-Test Split**: Split your data into training and testing sets to evaluate the model\\'s performance.\\n4. **Model Initialization and Training**: Initialize the `ExplainableBoostingClassifier` with the `monotonic_constraints` parameter set to enforce monotonic behavior on the \\'Time\\' feature.\\n5. **Evaluation**: Print out the accuracy scores on both training and test sets to get a baseline understanding of your model\\'s performance. \\n6. **Visualization**: Visualize the learned global explanations to understand how the model interprets the features, including \\'Time\\'.\\n\\nMake sure to replace placeholder values like `\\'Time\\'` and `your_dataset.csv` with actual names relevant to your specific dataset.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion3 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are data science assistant helping me solve code-related problems in my machine learning tasks.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I have trained an explainable boosting machine (EBM) for a binary classification task to predict if a flight will be delayed or not. Write python code to enforce monotonic constraints on the 'Time' feature in the most efficient way.\"}\n",
    "    ]\n",
    ")\n",
    "print(completion3.choices[0].message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T14:56:14.875371Z",
     "start_time": "2024-06-14T14:56:01.853168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Great! Explainable Boosting Machine (EBM) is a powerful tool for creating interpretable models. EBM models are inherently simple, and they make it easy to inject domain knowledge where needed. Given your certainty that higher values in 'Time' correlate with a higher chance of a flight being delayed, we can use the `interpret.glassbox` module in the `interpret` package to adjust the EBM model to respect this monotonicity constraint.\\n\\nHere's a step-by-step guide to achieve this:\\n\\n1. Load your trained EBM model.\\n2. Set the monotonicity constraint on the 'Time' feature.\\n3. Retrain the EBM model with the constraint.\\n4. Validate the adjusted model.\\n\\n### Step-by-Step Implementation\\n\\n1. **Load your trained EBM model:**\\n\\n   Ensure you have the `interpret` package installed:\\n   \\n   ```bash\\n   pip install interpret\\n   ```\\n\\n   Then, load your model (assuming you've already saved it):\\n\\n   ```python\\n   import joblib\\n   from interpret.glassbox import ExplainableBoostingClassifier\\n   \\n   # Load the saved EBM model\\n   ebm = joblib.load('ebm_model.pkl')\\n   ```\\n\\n2. **Set the monotonicity constraint on the 'Time' feature:**\\n\\n   When training the EBM, you can apply monotonic constraints directly. Since you've already trained your model, weâ€™ll have to reconstruct it with the monotonic constraint:\\n\\n   ```python\\n   from interpret.glassbox import ExplainableBoostingClassifier\\n   \\n   # Assuming 'Time' is indexed at 0 in the feature list \\n   # (you might need to adjust the index according to your data)\\n   feature_names = ebm.feature_names  # Get the feature names from the existing model\\n   time_index = feature_names.index('Time')  # Find the index of the 'Time' feature\\n   \\n   # Apply monotonic constraints\\n   ebm_monotonic = ExplainableBoostingClassifier(monotonicity_list=[(time_index, 1)])  # 1 for positive monotonicity\\n   ```\\n\\n3. **Retrain the EBM model with the constraint:**\\n\\n   You need to retrain the model with the new configuration. You'll use the same data you initially trained on.\\n\\n   ```python\\n   # Assuming you have your training data in X_train and y_train\\n   ebm_monotonic.fit(X_train, y_train)\\n   ```\\n\\n4. **Validate the adjusted model:**\\n\\n   Ensure that the new model with the constraint is performing as expected:\\n\\n   ```python\\n   from interpret import show\\n   \\n   # Evaluate the new model\\n   test_predictions = ebm_monotonic.predict(X_test)\\n   test_prob = ebm_monotonic.predict_proba(X_test)[:, 1]\\n   \\n   # Calculate metrics if needed\\n   from sklearn.metrics import accuracy_score, roc_auc_score\\n   \\n   accuracy = accuracy_score(y_test, test_predictions)\\n   roc_auc = roc_auc_score(y_test, test_prob)\\n   \\n   print(f'Accuracy: {accuracy}')\\n   print(f'ROC AUC: {roc_auc}')\\n   \\n   # Display the EBM to check the constraints\\n   ebm_local = ebm_monotonic.explain_global()\\n   show(ebm_local)\\n   ```\\n\\n   This way, we re-train the EBM ensuring the monotonic relationship you specified is upheld.\\n\\n**Note:** If 'Time' is not directly indexed as `0`, find the correct index by inspecting the `feature_names` list from the loaded EBM model.\\n\\n```python\\nprint(ebm.feature_names)\\n```\\n\\nThis should give you a list of features from which you can correctly identify the index of the 'Time' feature and proceed accordingly.\\n\\nBy following these steps, you should be able to enforce the constraint that higher 'Time' values correlate with a higher probability of flight delays in your EBM model.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Include domain knowledge without mentioning monotonic constraints\n",
    "\n",
    "completion4 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a skilled data scientist helping me, a business analyst, implementing machine learning tasks in python.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I have trained an explainable boosting machine (EBM) for a binary classification task to predict if a flight will be delayed or not. The training data and EBM contain a feature called 'Time' that indicates the starting time of a flight. From my expertise I know with certainty that a higher value in 'Time' correlates to a higher chance of a flight being delayed. Please have this be reflected in the EBM.\"}\n",
    "    ]\n",
    ")\n",
    "print(completion4.choices[0].message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T15:09:47.672703Z",
     "start_time": "2024-06-14T15:09:34.486454Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
