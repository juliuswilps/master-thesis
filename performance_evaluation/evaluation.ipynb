{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, average_precision_score,\n",
    "    precision_score, recall_score, f1_score, log_loss\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression,\n",
    "    \"RF\": RandomForestClassifier,\n",
    "    \"XGB\": XGBClassifier,\n",
    "    \"EBM\": ExplainableBoostingClassifier,\n",
    "}\n",
    "\n",
    "with open(\"hpo_grid.json\", \"r\") as f:\n",
    "    hpo_grid = json.load(f)\n",
    "\n",
    "n_folds = 5\n",
    "random_state = 42\n",
    "\n",
    "df = pd.read_csv(\"heloc-preprocessed-simple.csv\")\n",
    "y = df[\"Loan Repaid\"]\n",
    "X = df.drop(columns=\"Loan Repaid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T15:28:43.637392Z",
     "start_time": "2025-02-28T15:28:43.632032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-26T23:38:04.422537Z",
     "start_time": "2025-02-26T23:33:26.604783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Model: EBM -- Fold: 1/5 -----\n",
      "Best hyperparameters: {'max_bins': 256, 'interactions': 10, 'outer_bags': 8, 'inner_bags': 4, 'random_state': 42}\n",
      "\n",
      "----- Model: EBM -- Fold: 2/5 -----\n",
      "Best hyperparameters: {'max_bins': 512, 'interactions': 20, 'outer_bags': 16, 'inner_bags': 4, 'random_state': 42}\n",
      "\n",
      "----- Model: EBM -- Fold: 3/5 -----\n",
      "Best hyperparameters: {'max_bins': 512, 'interactions': 20, 'outer_bags': 16, 'inner_bags': 4, 'random_state': 42}\n",
      "\n",
      "----- Model: EBM -- Fold: 4/5 -----\n",
      "Best hyperparameters: {'max_bins': 512, 'interactions': 20, 'outer_bags': 16, 'inner_bags': 4, 'random_state': 42}\n",
      "\n",
      "----- Model: EBM -- Fold: 5/5 -----\n",
      "Best hyperparameters: {'max_bins': 256, 'interactions': 20, 'outer_bags': 16, 'inner_bags': 0, 'random_state': 42}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73       819\n",
      "           1       0.70      0.73      0.71       750\n",
      "\n",
      "    accuracy                           0.72      1569\n",
      "   macro avg       0.72      0.72      0.72      1569\n",
      "weighted avg       0.72      0.72      0.72      1569\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "['scalers.pkl']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use KFold (not stratified) since dataset is fairly balanced (48:52)\n",
    "outer_cv = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "results = []\n",
    "\n",
    "# TODO: Save best EBM (based roc-auc score)\n",
    "\n",
    "# Iterate over each model\n",
    "for model_name, hyperparams in hpo_grid.items():\n",
    "    print(f\"\\n===== Evaluating Model: {model_name} =====\")\n",
    "\n",
    "    if model_name == \"EBM\":\n",
    "        best_ebm = None\n",
    "        best_ebm_roc_auc = float('-inf')\n",
    "        best_ebm_ct = None\n",
    "        best_ebm_test_X = None\n",
    "        best_ebm_test_y = None\n",
    "\n",
    "    # Run 5-fold cross-validation\n",
    "    for fold_i, (train_val_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "        print(f\"\\n----- Model: {model_name} -- Fold: {fold_i + 1}/{n_folds} -----\")\n",
    "\n",
    "        # Split train-val and test set for fold\n",
    "        X_train_val, y_train_val = X.iloc[train_val_idx], y.iloc[train_val_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Split train-val into train and val for hpo\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=random_state\n",
    "        )\n",
    "\n",
    "        scaler = ColumnTransformer([(\"num\", StandardScaler(), X.columns)])\n",
    "        X_train_scaled = scaler.fit_transform(X_train)  # Fit ONLY on current train set\n",
    "        X_val_scaled = scaler.transform(X_val)  # Use same scaler on val set\n",
    "        X_test_scaled = scaler.transform(X_test) # Use same scaler on test set\n",
    "\n",
    "        # Track best HPs per fold\n",
    "        best_fold_hp_config = None\n",
    "        best_fold_loss = np.inf\n",
    "        best_fold_model = None\n",
    "\n",
    "        # Grid search over hyperparameters\n",
    "        for hp in product(*hyperparams.values()):\n",
    "            params = dict(zip(hyperparams.keys(), hp))\n",
    "\n",
    "            # Initialize and train model\n",
    "            model = models[model_name](**params)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            # TODO is this correct?? Should I use predict_proba() and log_loss or something else?\n",
    "            # TODO -> All models have predict_proba() -> remove else statements?\n",
    "            y_val_pred_proba = model.predict_proba(X_val_scaled) if hasattr(model, \"predict_proba\") else model.predict(X_val)\n",
    "            ce_loss = log_loss(y_val, y_val_pred_proba) if hasattr(model, \"predict_proba\") else np.nan\n",
    "\n",
    "            if ce_loss < best_fold_loss:\n",
    "                best_fold_loss = ce_loss\n",
    "                best_fold_hp_config = params\n",
    "                best_fold_model = model  # Store the best model found\n",
    "\n",
    "        # After the grid search, select the best model and print hyperparameters\n",
    "        print(f\"Best hyperparameters for {model_name} in Fold {fold_i + 1}: {best_fold_hp_config}\")\n",
    "\n",
    "        for dataset_name, X, y in [\n",
    "            (\"train\", X_train_scaled, y_train),\n",
    "            (\"val\", X_val_scaled, y_val),\n",
    "            (\"test\", X_test_scaled, y_test),\n",
    "        ]:\n",
    "            y_pred = best_fold_model.predict(X)\n",
    "            # TODO: Why indexing in this way?\n",
    "            y_pred_proba = best_fold_model.predict_proba(X)[:, 1] if hasattr(best_fold_model, \"predict_proba\") else None\n",
    "\n",
    "            scores = {\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold_i + 1,\n",
    "                \"dataset\": dataset_name,\n",
    "                \"accuracy\": accuracy_score(y, y_pred),\n",
    "                \"roc_auc\": roc_auc_score(y, y_pred_proba, average=\"macro\") if y_pred_proba is not None else np.nan,\n",
    "                \"pr_auc\": average_precision_score(y, y_pred_proba, average=\"macro\") if y_pred_proba is not None else np.nan,\n",
    "                \"precision\": precision_score(y, y_pred, average=\"macro\", zero_division=0),\n",
    "                \"recall\": recall_score(y, y_pred, average=\"macro\", zero_division=0),\n",
    "                \"f1_score\": f1_score(y, y_pred, average=\"macro\")\n",
    "            }\n",
    "\n",
    "            if model_name == \"EBM\" and scores[\"roc_auc\"] > best_ebm_roc_auc:\n",
    "                best_ebm = best_fold_model\n",
    "                best_ebm_roc_auc = scores[\"roc_auc\"]\n",
    "                best_ebm_ct = scaler\n",
    "                best_ebm_test_X = X_test\n",
    "                best_ebm_test_y = y_test\n",
    "\n",
    "            results.append(scores)\n",
    "\n",
    "    #TODO: best_ebm ist skaliert -> Shape Functions sind nicht interpretierbar\n",
    "    if model_name == \"EBM\":\n",
    "        joblib.dump(best_ebm, \"best-ebm.pkl\")\n",
    "        #TODO: Save scaler, X_test and y_test of best_ebm fold\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"evaluation_results.csv\", index=False)\n",
    "print(\"Results saved to evaluation_results.csv\")\n",
    "\n",
    "# Save model\n",
    "#joblib.dump(final_model, \"final_ebm_standardized_model.pkl\")\n",
    "#joblib.dump(scaler, \"scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
