{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"heloc_preprocessed.csv\")\n",
    "\n",
    "simple_feature_names = [\"Overall Credit Risk Score\", \"Months Since First Credit Account\", \"Average Age of Credit Accounts\", \"Number of Well-Maintained Accounts\", \"Percentage of Accounts Never Late\",\n",
    "                            \"Months Since Last Missed Payment\", \"Percentage of Installment vs Revolving Loans\", \"Time Since Last Credit Application\", \"Credit Utilization Ratio\", \"Number of Active Credit Cards/Lines\", \"Loan Repaid\"]\n",
    "\n",
    "df_simple = df.copy()\n",
    "df_simple.columns = simple_feature_names\n",
    "\n",
    "y = df_simple[\"Loan Repaid\"]\n",
    "X = df_simple.drop(columns=\"Loan Repaid\")\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T16:45:21.452110Z",
     "start_time": "2025-02-26T16:45:21.428347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "n_folds = 5\n",
    "random_state = 42\n",
    "verbose = 2\n",
    "\n",
    "best_hpo_config_csvs = []\n",
    "    for i in range(1, n_folds + 1):\n",
    "        if not os.path.exists(f\"{directory}/hpo_best_config_Fold_{i}.csv\"):\n",
    "            best_hpo_config_csvs.append(\n",
    "                pd.DataFrame(\n",
    "                    index=classification_datasets + regression_datasets,\n",
    "                    columns=traditional_models_to_run + gam_models_to_run,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            best_hpo_config_csvs.append(\n",
    "                pd.read_csv(\n",
    "                    f\"{directory}/hpo_best_config_Fold_{i}.csv\", index_col=0, header=0\n",
    "                )\n",
    "            )\n",
    "\n",
    "hyperparameter_config_file = \"./default_hyperparams.json\"\n",
    "\n",
    "with open(hyperparameter_config_file, \"r\") as read_file:\n",
    "    hpo_grid = json.load(read_file)\n",
    "\n",
    "# TODO: Add XGB hyperparameters\n",
    "keys, values = zip(*hpo_grid['EBM'].items())\n",
    "permutations_dicts = [\n",
    "                dict(zip(keys, v)) for v in itertools.product(*values)\n",
    "            ]\n",
    "\n",
    "# Use regular KFold because dataset is fairly balanced (0 = 5459, 1 = 5000)\n",
    "outer_cv = KFold(\n",
    "    n_splits=n_folds, shuffle=True, random_state=random_state\n",
    ")\n",
    "model_name = \"EBM\"\n",
    "for fold_i, (train_val_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    print(\n",
    "                    \"\\n\",\n",
    "                    \"-\" * 5,\n",
    "                    \"Model:\",\n",
    "                    model_name,\n",
    "                    \"-- Fold:\",\n",
    "                    fold_i + 1,\n",
    "                    \"/\",\n",
    "                    n_folds,\n",
    "                    \"-\" * 5,\n",
    "                )\n",
    "    X_train_val, y_train_val = X.iloc[train_val_idx], y.iloc[train_val_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "    num_pipe = Pipeline([(\"scaler\", StandardScaler())])\n",
    "    ct = ColumnTransformer(transformers=[(\"num\", num_pipe, X.columns.tolist())])\n",
    "\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        test_size=0.25,\n",
    "        stratify=y_train_val,\n",
    "        random_state=1337,\n",
    "    )\n",
    "\n",
    "    ct.fit(X_train)\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "        ct.transform(X_train), columns=ct.get_feature_names_out()\n",
    "    )\n",
    "    X_val = pd.DataFrame(\n",
    "        ct.transform(X_val), columns=ct.get_feature_names_out()\n",
    "    )\n",
    "    all_transformed_feature_names = ct.get_feature_names_out()\n",
    "\n",
    "    # Now you have the correctly mapped and ordered lists of transformed feature names\n",
    "    transformed_numerical_names = [\n",
    "        name\n",
    "        for name in all_transformed_feature_names\n",
    "        if name.startswith(\"num__\")\n",
    "    ]\n",
    "    transformed_categorical_names = [\n",
    "        name\n",
    "        for name in all_transformed_feature_names\n",
    "        if name.startswith(\"cat__\")\n",
    "    ]\n",
    "\n",
    "    print(\"Dataset Categorical Columns:\", dataset.categorical_cols)\n",
    "    print(\"Dataset Numerical Columns:\", dataset.numerical_cols)\n",
    "\n",
    "    print(\"Transformed Categorical Columns:\", transformed_categorical_names)\n",
    "    print(\"Transformed Numerical Columns:\", transformed_numerical_names)\n",
    "\n",
    "    if model_name == \"MLP\":\n",
    "        X_train = X_train.values\n",
    "        X_val = X_val.values\n",
    "\n",
    "    if verbose == 1:\n",
    "        print(\"\")\n",
    "\n",
    "    best_hp_config = None\n",
    "    best_loss = np.inf\n",
    "    training_time_of_best_model = np.inf\n",
    "    timings_hpo = []\n",
    "    # tuning hyperparameters in case of multiple hyperparameter candidates\n",
    "    logger.set_current_dataset_model_dir(dataset_name, model_name)\n",
    "\n",
    "    for id, arg_dict in enumerate(permutations_dicts):\n",
    "        # print the progress with replacing in line all the time\n",
    "        if verbose == 1:\n",
    "            print(\n",
    "                \"\\r\",\n",
    "                \"Progress: \",\n",
    "                id + 1,\n",
    "                \"/\",\n",
    "                len(permutations_dicts),\n",
    "                end=\"\",\n",
    "            )\n",
    "        elif verbose == 2:\n",
    "            print(\"-\" * 20)\n",
    "            print(arg_dict)\n",
    "\n",
    "        # define the model\n",
    "        model = Model(\n",
    "            model_name,\n",
    "            task,\n",
    "            arg_dict,\n",
    "            num_cols=transformed_numerical_names,\n",
    "            cat_cols=transformed_categorical_names,\n",
    "        )\n",
    "\n",
    "        start_training_time = datetime.now()\n",
    "\n",
    "        try:\n",
    "            # fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "        except (LinAlgError, OptimizationError) as e:\n",
    "            print(e)\n",
    "            warnings.warn(\n",
    "                \"Training with this hp combination, Error in Gaminet (Optimization Error, warm start) or Pygam (LinAlgError) possible\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        training_time = (\n",
    "            datetime.now() - start_training_time\n",
    "        ).total_seconds()\n",
    "        timings_hpo.append(training_time)\n",
    "\n",
    "        if task == \"classification\":\n",
    "            # calculate the loss\n",
    "            y_pred = model.predict(X_val)\n",
    "            ce_loss = log_loss(y_val, y_pred)\n",
    "\n",
    "            if ce_loss < best_loss:\n",
    "                best_hp_config = arg_dict\n",
    "                best_loss = ce_loss\n",
    "                training_time_of_best_model = training_time\n",
    "\n",
    "    best_hpo_string = (\n",
    "        str(best_hp_config)\n",
    "        .replace(\"{\", \"\")\n",
    "        .replace(\"}\", \"\")\n",
    "        .replace(\",\", \"\\n\")\n",
    "    )\n",
    "    best_hpo_config_csvs[fold_i].loc[\n",
    "        dataset_name, model_name\n",
    "    ] = best_hpo_string\n",
    "\n",
    "    # now take the best hpo config and retrain on X_train_val and y_train_val\n",
    "    ct_test = ColumnTransformer(transformers=transformers)\n",
    "    ct_test.fit(X_train_val)\n",
    "\n",
    "    X_train_val = pd.DataFrame(\n",
    "        ct_test.transform(X_train_val),\n",
    "        columns=ct_test.get_feature_names_out(),\n",
    "    )\n",
    "    X_test = pd.DataFrame(\n",
    "        ct_test.transform(X_test),\n",
    "        columns=ct_test.get_feature_names_out(),\n",
    "    )\n",
    "\n",
    "    all_transformed_feature_names = ct_test.get_feature_names_out()\n",
    "\n",
    "    transformed_numerical_names = [\n",
    "        name\n",
    "        for name in all_transformed_feature_names\n",
    "        if name.startswith(\"num__\")\n",
    "    ]\n",
    "    transformed_categorical_names = [\n",
    "        name\n",
    "        for name in all_transformed_feature_names\n",
    "        if name.startswith(\"cat__\")\n",
    "    ]\n",
    "\n",
    "    # Now you have the correctly mapped and ordered lists of transformed feature names\n",
    "    print(\"Transformed Categorical Columns:\", transformed_categorical_names)\n",
    "    print(\"Transformed Numerical Columns:\", transformed_numerical_names)\n",
    "\n",
    "    if model_name == \"MLP\":\n",
    "        X_train_val = X_train_val.values\n",
    "        X_test = X_test.values\n",
    "\n",
    "    best_model = Model(\n",
    "        model_name,\n",
    "        task,\n",
    "        best_hp_config,\n",
    "        num_cols=transformed_numerical_names,\n",
    "        cat_cols=transformed_categorical_names,\n",
    "    )\n",
    "    try:\n",
    "        best_model.fit(X_train_val, y_train_val)\n",
    "    except (OptimizationError, LinAlgError) as e:\n",
    "        print(e)\n",
    "        warnings.warn(\n",
    "            \"Training with this hp combination, Error in Gaminet (Optimization Error, warm start) or Pygam (LinAlgError) possible\"\n",
    "        )\n",
    "        continue\n",
    "    else:\n",
    "        # evaluate the retrained best model on the hold out dataset\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        if task == \"classification\":\n",
    "            y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "    if task == \"classification\":\n",
    "        logger.log_classification_report(\n",
    "            y_true=y_test, y_pred=y_pred, dataset=dataset, k_fold=fold_i\n",
    "        )\n",
    "        logger.log_roc_auc(\n",
    "            y_true=y_test, y_pred_confidence=y_pred_proba, k_fold=fold_i\n",
    "        )\n",
    "    elif task == \"regression\":\n",
    "        logger.log_regression_report(\n",
    "            y_true=y_test, y_pred=y_pred, k_fold=fold_i\n",
    "        )\n",
    "\n",
    "    logger.log_timing(\n",
    "        training_time_of_best_model, np.mean(timings_hpo), fold_i\n",
    "    )\n",
    "\n",
    "for i in range(n_folds):\n",
    "    best_hpo_config_csvs[i].to_csv(\n",
    "        f\"{directory}/hpo_best_config_Fold_{i + 1}.csv\",\n",
    "        index=True,\n",
    "        header=True,\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
