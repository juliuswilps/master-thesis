{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from load_api_key import load_openai_api_key\n",
    "import ast\n",
    "from caafe.run_llm_code import check_ast\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "key = load_openai_api_key()\n",
    "client = OpenAI(api_key=key)\n",
    "\n",
    "df = pd.read_csv(\"../../SyntheticData/synthetic_life_expectancy.csv\")\n",
    "ds = [\"A medical dataset containing patient information on life expectancy.\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:15:14.254891Z",
     "start_time": "2024-11-13T21:15:14.228386Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Changed ds[4][-1] to df.columns[-1], both being the target column name\n",
    "\n",
    "def get_prompt(\n",
    "    df, iterative=1, data_description_unparsed=None, samples=None, **kwargs\n",
    "):\n",
    "    how_many = (\n",
    "        \"up to 10 useful columns. Generate as many features as useful for downstream classifier, but as few as necessary to reach good performance.\"\n",
    "        if iterative == 1\n",
    "        else \"exactly one useful column\"\n",
    "    )\n",
    "    return f\"\"\"\n",
    "    The dataframe `df` is loaded and in memory. Columns are also named attributes.\n",
    "    Description of the dataset in `df` (column dtypes might be inaccurate):\n",
    "    \"{data_description_unparsed}\"\n",
    "\n",
    "    Columns in `df` (true feature dtypes listed here, categoricals encoded as int):\n",
    "    {samples}\n",
    "\n",
    "    This code was written by an expert datascientist working to improve predictions. It is a snippet of code that adds new columns to the dataset.\n",
    "    Number of samples (rows) in training dataset: {int(len(df))}\n",
    "\n",
    "    This code generates additional columns that are useful for a downstream classification algorithm (such as XGBoost) predicting \\\"{df.columns[-1]}\\\".\n",
    "    Additional columns add new semantic information, that is they use real world knowledge on the dataset. They can e.g. be feature combinations, transformations, aggregations where the new column is a function of the existing columns.\n",
    "    The scale of columns and offset does not matter. Make sure all used columns exist. Follow the above description of columns closely and consider the datatypes and meanings of classes.\n",
    "    This code also drops columns, if these may be redundant and hurt the predictive performance of the downstream classifier (Feature selection). Dropping columns may help as the chance of overfitting is lower, especially if the dataset is small.\n",
    "    The classifier will be trained on the dataset with the generated columns and evaluated on a holdout set. The evaluation metric is accuracy. The best performing code will be selected.\n",
    "    Added columns can be used in other codeblocks, dropped columns are not available anymore.\n",
    "\n",
    "    Code formatting for each added column:\n",
    "    ```python\n",
    "    # (Feature name and description)\n",
    "    # Usefulness: (Description why this adds useful real world knowledge to classify \\\"{df.columns[-1]}\\\" according to dataset description and attributes.)\n",
    "    # Input samples: (Three samples of the columns used in the following code, e.g. '{df.columns[0]}': {list(df.iloc[:3, 0].values)}, '{df.columns[1]}': {list(df.iloc[:3, 1].values)}, ...)\n",
    "    (Some pandas code using {df.columns[0]}', '{df.columns[1]}', ... to add a new column for each row in df)\n",
    "    ```end\n",
    "\n",
    "    Code formatting for dropping columns:\n",
    "    ```python\n",
    "    # Explanation why the column XX is dropped\n",
    "    df.drop(columns=['XX'], inplace=True)\n",
    "    ```end\n",
    "\n",
    "    Each codeblock generates {how_many} and can drop unused columns (Feature selection).\n",
    "    Each codeblock ends with ```end and starts with \"```python\"\n",
    "    Codeblock:\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:16:07.487084Z",
     "start_time": "2024-11-13T21:16:07.479141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def build_prompt_from_df(ds, df, iterative=1):\n",
    "    data_description_unparsed = ds[-1]\n",
    "    feature_importance = {}  # xgb_eval(_obj)\n",
    "\n",
    "    samples = \"\"\n",
    "    df_ = df.head(10)\n",
    "    for i in list(df_):\n",
    "        # show the list of values\n",
    "        nan_freq = \"%s\" % float(\"%.2g\" % (df[i].isna().mean() * 100))\n",
    "        s = df_[i].tolist()\n",
    "        if str(df[i].dtype) == \"float64\":\n",
    "            s = [round(sample, 2) for sample in s]\n",
    "        samples += (\n",
    "            f\"{df_[i].name} ({df[i].dtype}): NaN-freq [{nan_freq}%], Samples {s}\\n\"\n",
    "        )\n",
    "\n",
    "    kwargs = {\n",
    "        \"data_description_unparsed\": data_description_unparsed,\n",
    "        \"samples\": samples,\n",
    "        \"feature_importance\": {\n",
    "            k: \"%s\" % float(\"%.2g\" % feature_importance[k]) for k in feature_importance\n",
    "        },\n",
    "    }\n",
    "\n",
    "    prompt = get_prompt(\n",
    "        df,\n",
    "        data_description_unparsed=data_description_unparsed,\n",
    "        iterative=iterative,\n",
    "        samples=samples,\n",
    "    )\n",
    "\n",
    "    return prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:16:11.033011Z",
     "start_time": "2024-11-13T21:16:11.029801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The dataframe `df` is loaded and in memory. Columns are also named attributes.\n",
      "    Description of the dataset in `df` (column dtypes might be inaccurate):\n",
      "    \"A medical dataset containing patient information on life expectancy.\"\n",
      "\n",
      "    Columns in `df` (true feature dtypes listed here, categoricals encoded as int):\n",
      "    Cigarettes per Day (int64): NaN-freq [0.0%], Samples [1, 7, 6, 1, 2, 17, 11, 0, 11, 4]\n",
      "Age (int64): NaN-freq [0.0%], Samples [58, 71, 48, 34, 62, 27, 40, 58, 77, 38]\n",
      "Diet Quality (object): NaN-freq [0.0%], Samples ['Poor', 'Poor', 'Average', 'Average', 'Average', 'Average', 'Average', 'Average', 'Average', 'Average']\n",
      "Life Expectancy (float64): NaN-freq [0.0%], Samples [70.6, 72.7, 81.6, 80.8, 73.4, 98.9, 89.0, 72.6, 77.9, 82.6]\n",
      "\n",
      "\n",
      "    This code was written by an expert datascientist working to improve predictions. It is a snippet of code that adds new columns to the dataset.\n",
      "    Number of samples (rows) in training dataset: 1000\n",
      "\n",
      "    This code generates additional columns that are useful for a downstream classification algorithm (such as XGBoost) predicting \"Life Expectancy\".\n",
      "    Additional columns add new semantic information, that is they use real world knowledge on the dataset. They can e.g. be feature combinations, transformations, aggregations where the new column is a function of the existing columns.\n",
      "    The scale of columns and offset does not matter. Make sure all used columns exist. Follow the above description of columns closely and consider the datatypes and meanings of classes.\n",
      "    This code also drops columns, if these may be redundant and hurt the predictive performance of the downstream classifier (Feature selection). Dropping columns may help as the chance of overfitting is lower, especially if the dataset is small.\n",
      "    The classifier will be trained on the dataset with the generated columns and evaluated on a holdout set. The evaluation metric is accuracy. The best performing code will be selected.\n",
      "    Added columns can be used in other codeblocks, dropped columns are not available anymore.\n",
      "\n",
      "    Code formatting for each added column:\n",
      "    ```python\n",
      "    # (Feature name and description)\n",
      "    # Usefulness: (Description why this adds useful real world knowledge to classify \"Life Expectancy\" according to dataset description and attributes.)\n",
      "    # Input samples: (Three samples of the columns used in the following code, e.g. 'Cigarettes per Day': [1, 7, 6], 'Age': [58, 71, 48], ...)\n",
      "    (Some pandas code using Cigarettes per Day', 'Age', ... to add a new column for each row in df)\n",
      "    ```end\n",
      "\n",
      "    Code formatting for dropping columns:\n",
      "    ```python\n",
      "    # Explanation why the column XX is dropped\n",
      "    df.drop(columns=['XX'], inplace=True)\n",
      "    ```end\n",
      "\n",
      "    Each codeblock generates up to 10 useful columns. Generate as many features as useful for downstream classifier, but as few as necessary to reach good performance. and can drop unused columns (Feature selection).\n",
      "    Each codeblock ends with ```end and starts with \"```python\"\n",
      "    Codeblock:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt_from_df(ds, df)\n",
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:16:12.551092Z",
     "start_time": "2024-11-13T21:16:12.542912Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert datascientist assistant solving Kaggle problems. You answer only by generating code. Answer as concisely as possible.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:16:23.455427Z",
     "start_time": "2024-11-13T21:16:23.448632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def generate_code(messages, client):\n",
    "    \"\"\"if model == \"skip\":\n",
    "        return \"\"\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stop=[\"```end\"],\n",
    "        temperature=0.5,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    code = completion.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\").replace(\"<end>\", \"\")\n",
    "    return code"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:16:34.630762Z",
     "start_time": "2024-11-13T21:16:34.621253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# (Cigarettes per Day to Age Ratio)\n",
      "# Usefulness: This feature represents the ratio of smoking to age, which may correlate with life expectancy as smoking is a known risk factor.\n",
      "# Input samples: 'Cigarettes per Day': [1, 7, 6], 'Age': [58, 71, 48]\n",
      "df['Cigarettes_Age_Ratio'] = df['Cigarettes per Day'] / (df['Age'] + 1)  # Adding 1 to avoid division by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = generate_code(messages, client)\n",
    "print(code)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:16:42.777706Z",
     "start_time": "2024-11-13T21:16:40.200251Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def run_llm_code(code: str, df: pd.DataFrame, convert_categorical_to_integer: Optional[bool] = True, fill_na: Optional[bool] = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executes the given code on the given dataframe and returns the resulting dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    code (str): The code to execute.\n",
    "    df (pandas.DataFrame): The dataframe to execute the code on.\n",
    "    convert_categorical_to_integer (bool, optional): Whether to convert categorical columns to integer values. Defaults to True.\n",
    "    fill_na (bool, optional): Whether to fill NaN values in object columns with empty strings. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The resulting dataframe after executing the code.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loc = {}\n",
    "        df = copy.deepcopy(df)\n",
    "\n",
    "        \"\"\"if fill_na and False:\n",
    "            df.loc[:, (df.dtypes == object)] = df.loc[:, (df.dtypes == object)].fillna(\n",
    "                \"\"\n",
    "            )\n",
    "        if convert_categorical_to_integer and False:\n",
    "            df = df.apply(convert_categorical_to_integer_f)\"\"\"\n",
    "\n",
    "        access_scope = {\"df\": df, \"pd\": pd, \"np\": np}\n",
    "        parsed = ast.parse(code)\n",
    "        check_ast(parsed)\n",
    "        exec(compile(parsed, filename=\"<ast>\", mode=\"exec\"), access_scope, loc)\n",
    "        df = copy.deepcopy(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Code could not be executed\", e)\n",
    "        raise (e)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:17:01.286072Z",
     "start_time": "2024-11-13T21:17:01.282591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "     Cigarettes per Day  Age Diet Quality  Life Expectancy  \\\n0                     1   58         Poor             70.6   \n1                     7   71         Poor             72.7   \n2                     6   48      Average             81.6   \n3                     1   34      Average             80.8   \n4                     2   62      Average             73.4   \n..                  ...  ...          ...              ...   \n995                  19   23      Average            102.1   \n996                  15   20         Poor             96.0   \n997                   3   68      Average             72.6   \n998                   5   59         Poor             74.3   \n999                   2   51      Average             76.7   \n\n     Cigarettes_Age_Ratio  \n0                0.016949  \n1                0.097222  \n2                0.122449  \n3                0.028571  \n4                0.031746  \n..                    ...  \n995              0.791667  \n996              0.714286  \n997              0.043478  \n998              0.083333  \n999              0.038462  \n\n[1000 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cigarettes per Day</th>\n      <th>Age</th>\n      <th>Diet Quality</th>\n      <th>Life Expectancy</th>\n      <th>Cigarettes_Age_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>58</td>\n      <td>Poor</td>\n      <td>70.6</td>\n      <td>0.016949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>71</td>\n      <td>Poor</td>\n      <td>72.7</td>\n      <td>0.097222</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>48</td>\n      <td>Average</td>\n      <td>81.6</td>\n      <td>0.122449</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>34</td>\n      <td>Average</td>\n      <td>80.8</td>\n      <td>0.028571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>62</td>\n      <td>Average</td>\n      <td>73.4</td>\n      <td>0.031746</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>19</td>\n      <td>23</td>\n      <td>Average</td>\n      <td>102.1</td>\n      <td>0.791667</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>15</td>\n      <td>20</td>\n      <td>Poor</td>\n      <td>96.0</td>\n      <td>0.714286</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>3</td>\n      <td>68</td>\n      <td>Average</td>\n      <td>72.6</td>\n      <td>0.043478</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>5</td>\n      <td>59</td>\n      <td>Poor</td>\n      <td>74.3</td>\n      <td>0.083333</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>2</td>\n      <td>51</td>\n      <td>Average</td>\n      <td>76.7</td>\n      <td>0.038462</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = run_llm_code(code, df)\n",
    "df_new"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T21:17:44.571703Z",
     "start_time": "2024-11-13T21:17:44.568599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
